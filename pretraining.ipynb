{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastText预训练词向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "维度为100维，其他值维默认"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]D:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:52: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      " 57%|█████████████████████████████████████████████▋                                  | 8/14 [1:06:56<45:40, 456.74s/it]"
     ]
    }
   ],
   "source": [
    "#fastText\n",
    "\n",
    "WORK_PATH = '.'\n",
    "\n",
    "class Word2VecTrainingMaster():\n",
    "\n",
    "    def __init__(self, new_work=True, corpus_path='D:/学习/NLP/中兴比赛/corpus.txt', work_path='.', base_name='fastText100.model', num_features=100, min_word_count=5, context=5, auto=True, batch_size=100000, step_save=False):\n",
    "\n",
    "        self.work_path = work_path\n",
    "        self.corpus_path = corpus_path\n",
    "        self.word2vec_model = self.make_word2vec_model(num_features, min_word_count, context)\n",
    "        self.base_name=base_name\n",
    "        self.word2vec_model.save(self.work_path + '/' + self.base_name)\n",
    "        self.step_save = step_save\n",
    "\n",
    "        if auto:\n",
    "\n",
    "            with open(self.corpus_path) as f:\n",
    "\n",
    "                reader = f.readlines()\n",
    "\n",
    "                f.close()\n",
    "\n",
    "            length = len(reader)\n",
    "\n",
    "        INIT = True\n",
    "        for batch_index in tqdm(range(0, length, batch_size)):\n",
    "                \n",
    "                batch = []\n",
    "                \n",
    "                for i in reader[batch_index: batch_index+batch_size]:\n",
    "                    \n",
    "                    batch.append(i.strip('\\n').split())\n",
    "\n",
    "                self.update_model(batch, init=INIT)\n",
    "\n",
    "                INIT = False\n",
    "\n",
    "        self.word2vec_model.save(self.work_path + '/' + self.base_name)\n",
    "\n",
    "    def make_word2vec_model(self, num_features, min_word_count, context):\n",
    "\n",
    "        return FastText(size=num_features, min_count=min_word_count, window=context)\n",
    "\n",
    "    def update_model(self, batch, init):\n",
    "\n",
    "        if init:\n",
    "            self.word2vec_model.build_vocab(batch)\n",
    "        else:\n",
    "            self.word2vec_model.build_vocab(batch, update=True)\n",
    "\n",
    "        self.word2vec_model.train(batch, total_examples=self.word2vec_model.corpus_count, epochs=self.word2vec_model.iter)\n",
    "\n",
    "        if self.step_save:\n",
    "\n",
    "            self.word2vec_model.save(self.work_path + '/' + self.base_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    w2v = Word2VecTrainingMaster(corpus_path='D:/学习/NLP/中兴比赛/corpus.txt', base_name = 'fastText.model', min_word_count=5, num_features=100, work_path=WORK_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec预训练词向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "维度为300维，其他值维默认"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]D:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:53: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 14/14 [33:09<00:00, 142.14s/it]\n"
     ]
    }
   ],
   "source": [
    "##word2vec\n",
    "\n",
    "\n",
    "WORK_PATH = '.'\n",
    "\n",
    "class Word2VecTrainingMaster():\n",
    "\n",
    "    def __init__(self, new_work=True, corpus_path= 'D:/学习/NLP/中兴比赛/corpus.txt', work_path='.', base_name='word2vec.model', num_features=300, min_word_count = 1, context=5, auto=True, batch_size=100000, step_save=False):\n",
    "\n",
    "        self.work_path = work_path\n",
    "        self.corpus_path = corpus_path\n",
    "        self.word2vec_model = self.make_word2vec_model(num_features, min_word_count, context)\n",
    "        self.base_name=base_name\n",
    "        self.word2vec_model.save(self.work_path + '/' + self.base_name)\n",
    "        self.step_save = step_save\n",
    "\n",
    "        if auto:\n",
    "\n",
    "            with open(self.corpus_path) as f:\n",
    "\n",
    "                reader = f.readlines()\n",
    "\n",
    "                f.close()\n",
    "\n",
    "            length = len(reader)\n",
    "\n",
    "        INIT = True\n",
    "        for batch_index in tqdm(range(0, length, batch_size)):\n",
    "                \n",
    "                batch = []\n",
    "                \n",
    "                for i in reader[batch_index: batch_index+batch_size]:\n",
    "                    \n",
    "                    batch.append(i.strip('\\n').split())\n",
    "\n",
    "                self.update_model(batch, init=INIT)\n",
    "\n",
    "                INIT = False\n",
    "\n",
    "        self.word2vec_model.save(self.work_path + '/' + self.base_name)\n",
    "\n",
    "    def make_word2vec_model(self, num_features, min_word_count, context):\n",
    "\n",
    "        return Word2Vec(size=num_features, min_count=min_word_count, window=context)\n",
    "\n",
    "    def update_model(self, batch, init):\n",
    "\n",
    "        if init:\n",
    "            self.word2vec_model.build_vocab(batch)\n",
    "        else:\n",
    "            self.word2vec_model.build_vocab(batch, update=True)\n",
    "\n",
    "        self.word2vec_model.train(batch, total_examples=self.word2vec_model.corpus_count, epochs=self.word2vec_model.iter)\n",
    "\n",
    "        if self.step_save:\n",
    "\n",
    "            self.word2vec_model.save(self.work_path + '/' + self.base_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    w2v = Word2VecTrainingMaster(corpus_path='D:/学习/NLP/中兴比赛/corpus.txt', num_features=300, work_path=WORK_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "w2v = Word2Vec.load('word2vec.model')\n",
    "print(bool('323'in w2v.wv.vocab.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove预训练词向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "时间关系没有在后面的模型中跑这个词向量模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove import Glove\n",
    "from glove import Corpus\n",
    "import pprint\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10 training epochs with 3 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n"
     ]
    }
   ],
   "source": [
    "corpus_model = Corpus()\n",
    "corpus_model.fit(batch[:1], window=5)\n",
    "glove = Glove(no_components=100, learning_rate=0.05)\n",
    "glove.fit(corpus_model.matrix, epochs=10,\n",
    "          no_threads=3, verbose=True)\n",
    "glove.add_dictionary(corpus_model.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'corpus_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a034cf52dfe8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mw2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWord2VecTrainingMaster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'D:/学习/NLP/中兴比赛/corpus.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwork_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mWORK_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-a034cf52dfe8>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, new_work, corpus_path, work_path, base_name, num_features, lr, context, auto, batch_size, step_save)\u001b[0m\n\u001b[0;32m     33\u001b[0m                     \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-a034cf52dfe8>\u001b[0m in \u001b[0;36mupdate_model\u001b[1;34m(self, batch, context)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2vec_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_threads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2vec_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_dictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_save\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'corpus_model' is not defined"
     ]
    }
   ],
   "source": [
    "##Glove\n",
    "\n",
    "WORK_PATH = '.'\n",
    "\n",
    "class Word2VecTrainingMaster():\n",
    "\n",
    "    def __init__(self, new_work=True, corpus_path= 'D:/学习/NLP/中兴比赛/corpus.txt', work_path='.', base_name='Glove.model', num_features=100, lr = 0.05, context=5, auto=True, batch_size=100000, step_save=False):\n",
    "\n",
    "        self.work_path = work_path\n",
    "        self.corpus_path = corpus_path\n",
    "        self.word2vec_model = self.make_word2vec_model(num_features, context, lr)\n",
    "        self.base_name=base_name\n",
    "        self.word2vec_model.save(self.work_path + '/' + self.base_name)\n",
    "        self.step_save = step_save\n",
    "        self.corpus_model = Corpus()\n",
    "\n",
    "        if auto:\n",
    "\n",
    "            with open(self.corpus_path) as f:\n",
    "\n",
    "                reader = f.readlines()\n",
    "\n",
    "                f.close()\n",
    "\n",
    "            length = len(reader)\n",
    "\n",
    "        for batch_index in tqdm(range(0, length, batch_size)):\n",
    "                \n",
    "                batch = []\n",
    "                \n",
    "                for i in reader[batch_index: batch_index+batch_size]:\n",
    "                    \n",
    "                    batch.append(i.strip('\\n').split())\n",
    "\n",
    "                self.update_model(batch, context)\n",
    "\n",
    "\n",
    "        self.word2vec_model.save(self.work_path + '/' + self.base_name)\n",
    "\n",
    "    def make_word2vec_model(self, num_features, context, lr):\n",
    "\n",
    "        return Glove(no_components=num_features, learning_rate=lr)\n",
    "\n",
    "    def update_model(self, batch, context):\n",
    "\n",
    "        self.corpus_model.fit(batch, window = context)\n",
    "\n",
    "        self.word2vec_model.fit(self.corpus_model.matrix, epochs=10, no_threads=3, verbose=False)\n",
    "        \n",
    "        self.word2vec_model.add_dictionary(corpus_model.dictionary)\n",
    "\n",
    "        if self.step_save:\n",
    "\n",
    "            self.word2vec_model.save(self.work_path + '/' + self.base_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    w2v = Word2VecTrainingMaster(corpus_path='D:/学习/NLP/中兴比赛/corpus.txt', num_features=100, work_path=WORK_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
